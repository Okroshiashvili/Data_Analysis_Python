{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join, Combine, and Reshape a DataFrame\n",
    "\n",
    "---\n",
    "\n",
    "Oftentimes, the data is in different files and in different format. The analyst have to be able to deal with such kind of problem and appropriately join different data files in order to do successful operations on the whole data and not only one part of it. In this lecture, we will cover one of the most important and slightly advanced functionalities of Pandas - how to join and combine several DataFrames along with somewhat familiar Pivoting and cross-tabulation operations.\n",
    "\n",
    "\n",
    "### Lecture outline\n",
    "\n",
    "---\n",
    "\n",
    "* Hierarchical Indexing (MultiIndex)\n",
    "\n",
    "\n",
    "* Combining and Merging\n",
    "\n",
    "\n",
    "* Joining and Concatenation\n",
    "\n",
    "\n",
    "* Reshaping and Pivoting\n",
    "\n",
    "\n",
    "    * Wide to Long format\n",
    "    \n",
    "    * Long to Wide format\n",
    "\n",
    "\n",
    "* Groupby\n",
    "\n",
    "\n",
    "* Pivot Table\n",
    "\n",
    "\n",
    "* Cross Tabulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T05:29:47.633957Z",
     "start_time": "2021-01-04T05:29:47.344874Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Hierarchical Indexing (MultiIndex)\n",
    "\n",
    "---\n",
    "\n",
    "Before we delve deep into Pandas merging and reshaping operations, it's essential to know what is a hierarchical index and how to work with it.\n",
    "\n",
    "Hierarchical indexing is an important feature of pandas that enables you to have multiple (two or more) index levels on an axis. Somewhat abstractly, it provides a way for you to work with higher dimensional data in a lower dimensional form, like Series (1d) and DataFrame (2d).\n",
    "\n",
    "\n",
    "> Note that, operations on hierarchical indexed DataFrame is different due to several indices. Hence, we have to differentiate which index to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Reference\n",
    "\n",
    "[MultiIndex / advanced indexing](https://pandas.pydata.org/pandas-docs/stable/user_guide/advanced.html)\n",
    "\n",
    "\n",
    "[Multiindexing](https://pandas.pydata.org/pandas-docs/stable/user_guide/cookbook.html#multiindexing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T13:48:07.243007Z",
     "start_time": "2021-01-01T13:48:07.235783Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "multi_df = pd.DataFrame(data=np.random.randint(100, size=9),\n",
    "                        index=[['a', 'a', 'a', 'b', 'b', 'c', 'c', 'd', 'd'],\n",
    "                               [1, 2, 3, 1, 3, 1, 2, 1, 3]],\n",
    "                        columns=[\"values\"])\n",
    "\n",
    "\n",
    "multi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T13:48:10.401587Z",
     "start_time": "2021-01-01T13:48:10.398732Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "multi_df.index # Return index object\n",
    "\n",
    "multi_df.index.levels # Return index levels\n",
    "\n",
    "multi_df.index.names # Return names in index levels. Currently no names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T13:48:10.657883Z",
     "start_time": "2021-01-01T13:48:10.652433Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "multi_df.index.names = [\"index_1\", \"index_2\"]\n",
    "\n",
    "multi_df.index.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T13:48:11.302089Z",
     "start_time": "2021-01-01T13:48:11.290721Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "multi_df.columns.names = [\"column_index\"]\n",
    "\n",
    "multi_df.columns.names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T13:11:07.651867Z",
     "start_time": "2021-01-01T13:11:07.639392Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "multi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T13:15:05.949535Z",
     "start_time": "2021-01-01T13:15:05.939258Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "multi_df.xs(key=\"a\", axis=0, level=0) # Get values at specified index\n",
    "\n",
    "multi_df.xs(key=2, axis=0, level=1) # Get values at specified index\n",
    "\n",
    "multi_df.xs(key=(\"a\", 3)) # Get values at several indexes\n",
    "\n",
    "multi_df.xs(key=(\"a\", 3), axis=0, level=[0, 1]) # Get values at several indexes and levels\n",
    "\n",
    "multi_df.xs(key=\"values\", axis=1) # Get values at vertical axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Instead of `xs()` method we can use familiar `loc` for slicing on different axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T13:18:31.487195Z",
     "start_time": "2021-01-01T13:18:31.480893Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "All = slice(None) # Python built-in slicer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T13:28:10.360081Z",
     "start_time": "2021-01-01T13:28:10.348853Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "multi_df.loc[\"a\"] # Slice at the first level\n",
    "\n",
    "multi_df.loc[[\"a\", \"c\"]] # Selective slice at the first level\n",
    "\n",
    "multi_df.loc[\"a\"].loc[:2] # Slice at the second level\n",
    "\n",
    "\n",
    "multi_df.loc[(\"a\", All), All] # Return all values for \"a\" index at the first level\n",
    "\n",
    "multi_df.loc[(All, 1), All] # Return all 1's from the second level\n",
    "\n",
    "multi_df.loc[(All, 1), (\"values\")] # Same as above one. Selects all first level index and \"1\" from the second level\n",
    "\n",
    "multi_df.loc[(slice(\"a\", \"c\"), 2), All] # Selective slicing at both index level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T13:27:46.433673Z",
     "start_time": "2021-01-01T13:27:46.426834Z"
    },
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Reordering and Sorting Levels\n",
    "\n",
    "---\n",
    "\n",
    "Sometimes, we need to swap the index levels and/or sort multiindex DataFrame by either one or both index. Here, comes the solution for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T13:37:07.490786Z",
     "start_time": "2021-01-01T13:37:07.484980Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "multi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T13:37:58.488720Z",
     "start_time": "2021-01-01T13:37:58.481942Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "multi_df.swaplevel(\"index_2\", \"index_1\") # Swap or change the index levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can sort multiindex DataFrame either by index or values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T13:39:42.371707Z",
     "start_time": "2021-01-01T13:39:42.363432Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "multi_df.sort_index(level=0) # Sort by index level 0\n",
    "\n",
    "multi_df.sort_index(level=1) # Sort by index level 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T13:40:13.329393Z",
     "start_time": "2021-01-01T13:40:13.323938Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "multi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T13:41:33.941732Z",
     "start_time": "2021-01-01T13:41:33.935514Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "multi_df.sort_values(by=(\"values\")) # Sort by column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Summary Statistics by Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T13:48:20.615012Z",
     "start_time": "2021-01-01T13:48:20.607696Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "multi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T13:49:21.850007Z",
     "start_time": "2021-01-01T13:49:21.842859Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "multi_df.sum() # Sum up all the values\n",
    "\n",
    "multi_df.sum(level=0) # Sum up numbers at the level 0\n",
    "\n",
    "multi_df.sum(level=1) # Sum up numbers at the level 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Other statistical and/or arithmetic functions works like that. We have to explicitly indicate at which level we want to perform the particular operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Set and Reset MultiIndex\n",
    "\n",
    "---\n",
    "\n",
    "We can set and hence reset multiple index in our DataFrame by using `set_index()` and `reset_index()` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T13:55:45.284392Z",
     "start_time": "2021-01-01T13:55:45.276159Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "multi_df.reset_index(level=0) # Reset level 0 index\n",
    "\n",
    "\n",
    "multi_df.reset_index(level=1) # Reset level 1 index\n",
    "\n",
    "\n",
    "multi_df.reset_index() # Reset all the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T13:56:24.921133Z",
     "start_time": "2021-01-01T13:56:24.917681Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "multi_df = multi_df.reset_index() # Reset index and set it again\n",
    "\n",
    "\n",
    "multi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T13:56:27.596649Z",
     "start_time": "2021-01-01T13:56:27.579966Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "multi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T13:58:29.832328Z",
     "start_time": "2021-01-01T13:58:29.811495Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "multi_df.set_index(keys=[\"index_1\", \"index_2\"]) # Set columns as index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "By default the columns are removed from the DataFrame. However, we can leave them inside DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T13:58:46.311858Z",
     "start_time": "2021-01-01T13:58:46.302946Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "multi_df.set_index(keys=[\"index_1\", \"index_2\"], drop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Combining and Merging\n",
    "\n",
    "---\n",
    "\n",
    "In this part we will see how we can bring multiple DataFrame objects together, either by merging them horizontally, or by concatenating them vertically, along with combining and joining DataFrames.\n",
    "\n",
    "\n",
    "* `merge()` - for combining data on common columns or indices\n",
    "\n",
    "\n",
    "    * supports inner/left/right/full\n",
    "    * can only join two DataFrames at a time\n",
    "    * supports column-column, index-column, index-index joins\n",
    "\n",
    "\n",
    "That's not all. We also see how Pandas `append()` method works.\n",
    "\n",
    "\n",
    "\n",
    "> Bonus: **CROSS JOIN** or **CARTESIAN PRODUCT**\n",
    "\n",
    "\n",
    "\n",
    "> Big Bonus: `merge_asof()` to merge on nearest keys rather than equal keys."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Reference\n",
    "\n",
    "\n",
    "[Merge, join, concatenate and compare](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html)\n",
    "\n",
    "\n",
    "[Merge](https://pandas.pydata.org/pandas-docs/stable/user_guide/cookbook.html#merge)\n",
    "\n",
    "\n",
    "[Pandas Merging 101](https://stackoverflow.com/questions/53645882/pandas-merging-101)\n",
    "\n",
    "\n",
    "[Database-style DataFrame or named Series joining/merging](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html#merging-join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Merging\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Database-Style joining.\n",
    "\n",
    "\n",
    "\n",
    "![Venn Diagram](images/merge.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T09:00:12.524257Z",
     "start_time": "2021-01-03T09:00:12.502520Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "left = pd.DataFrame({'key': ['A', 'B', 'C', 'D'],\n",
    "                     'value': [10, 20, 30, 40]})\n",
    "\n",
    "\n",
    "left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T09:00:12.720999Z",
     "start_time": "2021-01-03T09:00:12.711098Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "right = pd.DataFrame({'key': ['B', 'D', 'E', 'F'],\n",
    "                      'value': [20, 40, 50, 60]})\n",
    "\n",
    "\n",
    "right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T09:00:13.171387Z",
     "start_time": "2021-01-03T09:00:13.154205Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.merge(left=left, right=right, how=\"inner\", on=\"key\") # Inner join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T09:00:13.439385Z",
     "start_time": "2021-01-03T09:00:13.425272Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.merge(left=left, right=right, how=\"left\", on=\"key\") # Left join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T09:00:13.644232Z",
     "start_time": "2021-01-03T09:00:13.630550Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.merge(left=left, right=right, how=\"right\", on=\"key\") # Right join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T09:00:13.868323Z",
     "start_time": "2021-01-03T09:00:13.852095Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.merge(left=left, right=right, how=\"outer\", on=\"key\") # Outer join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "If the column name we are merging on are different, we can use `right_on` and `left_on` arguments inside `merge()` function. To see these features in action, let modify our DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T09:00:14.836714Z",
     "start_time": "2021-01-03T09:00:14.831702Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "left = left.rename({\"key\": \"first_left_key\"}, axis=1)\n",
    "\n",
    "left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T09:00:15.174117Z",
     "start_time": "2021-01-03T09:00:15.163901Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "right = right.rename({\"key\": \"first_right_key\"}, axis=1)\n",
    "\n",
    "right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T09:00:15.503884Z",
     "start_time": "2021-01-03T09:00:15.491717Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.merge(left=left, right=right, how=\"inner\", left_on=\"first_left_key\", right_on=\"first_right_key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What if we want to use two or more columns for merging? That's not a problem. First of all, we need to add new columns to our DataFrames to perform multiple column merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T09:00:17.401737Z",
     "start_time": "2021-01-03T09:00:17.382906Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "left = left.rename({\"first_left_key\": \"key_1\"}, axis=1)\n",
    "\n",
    "left.insert(1, \"key_2\", left[\"key_1\"].str.lower())\n",
    "\n",
    "left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T09:00:17.677874Z",
     "start_time": "2021-01-03T09:00:17.666834Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "right = right.rename({\"first_right_key\": \"key_1\"}, axis=1)\n",
    "\n",
    "right.insert(1, \"key_2\", right[\"key_1\"].str.lower())\n",
    "\n",
    "right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T09:00:17.950426Z",
     "start_time": "2021-01-03T09:00:17.932367Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.merge(left=left, right=right, how=\"inner\", on=[\"key_1\", \"key_2\"]) # Inner join with multiple key\n",
    "\n",
    "\n",
    "left.merge(right=right, how=\"inner\", on=[\"key_1\", \"key_2\"]) # Same as above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can also merge DataFrames by using the index. To do so, first we need to set index for our DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T09:00:18.967431Z",
     "start_time": "2021-01-03T09:00:18.961632Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "left = left.set_index(\"key_1\")\n",
    "\n",
    "left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T09:00:19.315841Z",
     "start_time": "2021-01-03T09:00:19.304368Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "right = right.set_index(\"key_1\")\n",
    "\n",
    "right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T09:00:19.677965Z",
     "start_time": "2021-01-03T09:00:19.665296Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.merge(left=left, right=right, how=\"inner\", left_index=True, right_index=True) # Inner join based on index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Cross Join\n",
    "\n",
    "---\n",
    "\n",
    "Cross Join is the same as Cartesian Product on `X-Y` plane\n",
    "\n",
    "![Venn Diagram](images/cross_join.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T09:00:20.912640Z",
     "start_time": "2021-01-03T09:00:20.897994Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T09:00:21.197587Z",
     "start_time": "2021-01-03T09:00:21.188173Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T09:00:22.377909Z",
     "start_time": "2021-01-03T09:00:22.364309Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "left.merge(right, how=\"cross\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### `append()`\n",
    "\n",
    "---\n",
    "\n",
    "Append rows of the second DataFrame to the end of the first DataFrame. Columns in the second DataFrame that are not in the first DataFrame are added as new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T09:00:27.144558Z",
     "start_time": "2021-01-03T09:00:27.138682Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "left.append(right, ignore_index=False) # Preserves the index of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T09:00:28.014530Z",
     "start_time": "2021-01-03T09:00:28.008763Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "left.append(right, ignore_index=True) # Resets the old index and sets new one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let add one more column to the right DataFrame to see if `append()` method really adds new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T09:00:36.937084Z",
     "start_time": "2021-01-03T09:00:36.928397Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "right[\"new_value\"] = right[\"value\"] * 2\n",
    "\n",
    "right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T09:00:37.323460Z",
     "start_time": "2021-01-03T09:00:37.311115Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "left.append(right, ignore_index=False) # Indeed, \"append()\" method adds new column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### `merge_asof()`\n",
    "\n",
    "---\n",
    "\n",
    "Pandas provides special functions for merging Time-series DataFrames. Perhaps the most useful and popular one is the `merge_asof()` function. The `merge_asof()` is similar to an ordered left-join merge except that you match on nearest key rather than equal keys. For each row in the left DataFrame, you select the last row in the right DataFrame whose on key is less than the left’s key. Both DataFrames must be sorted by the key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Reference\n",
    "\n",
    "\n",
    "[pandas.merge_asof](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.merge_asof.html#pandas-merge-asof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T09:00:43.542601Z",
     "start_time": "2021-01-03T09:00:43.526124Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trades = pd.DataFrame({'time': pd.to_datetime(['20160525 13:30:00.023',\n",
    "                                               '20160525 13:30:00.038',\n",
    "                                               '20160525 13:30:00.048',\n",
    "                                               '20160525 13:30:00.048',\n",
    "                                               '20160525 13:30:00.048']),\n",
    "                       'ticker': ['MSFT', 'MSFT','GOOG', 'GOOG', 'AAPL'],\n",
    "                       'price': [51.95, 51.95,720.77, 720.92, 98.00],\n",
    "                       'quantity': [75, 155,100, 100, 100]},\n",
    "                      columns=['time', 'ticker', 'price', 'quantity'])\n",
    "\n",
    "\n",
    "\n",
    "trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T09:00:44.172465Z",
     "start_time": "2021-01-03T09:00:44.148399Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "quotes = pd.DataFrame({'time': pd.to_datetime(['20160525 13:30:00.023',\n",
    "                                               '20160525 13:30:00.023',\n",
    "                                               '20160525 13:30:00.030',\n",
    "                                               '20160525 13:30:00.041',\n",
    "                                               '20160525 13:30:00.048',\n",
    "                                               '20160525 13:30:00.049',\n",
    "                                               '20160525 13:30:00.072',\n",
    "                                               '20160525 13:30:00.075']),\n",
    "                       'ticker': ['GOOG', 'MSFT', 'MSFT','MSFT', 'GOOG', 'AAPL', 'GOOG','MSFT'],\n",
    "                       'bid': [720.50, 51.95, 51.97, 51.99,720.50, 97.99, 720.50, 52.01],\n",
    "                       'ask': [720.93, 51.96, 51.98, 52.00,720.93, 98.01, 720.88, 52.03]},\n",
    "                      columns=['time', 'ticker', 'bid', 'ask'])\n",
    "\n",
    "\n",
    "quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T09:00:44.949601Z",
     "start_time": "2021-01-03T09:00:44.934840Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.merge_asof(trades, quotes, on=\"time\", by=\"ticker\") # Approximate or nearest merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "If you observe carefully, you can notice the reason behind `NaN` appearing in the `AAPL` ticker row. Since the right DataFrame quotes didn't have any time value less than `13:30:00.048` (the time in the left table) for `AAPL` ticker, `NaN`s were introduced in the bid and ask columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Combining\n",
    "\n",
    "---\n",
    "\n",
    "There is another data combination situation that can’t be expressed as either a merge or concatenation operation. Imagine the situation of having two datasets whose indexes overlap in full or part.\n",
    "\n",
    "As a motivating example, consider NumPy’s `where()` function, which performs the array-oriented equivalent of an `if-else` expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T07:55:45.094474Z",
     "start_time": "2021-01-02T07:55:45.082266Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "series_1 = pd.Series([np.nan, 2.5, np.nan, 3.5, 4.5, np.nan],\n",
    "                     index=['f', 'e', 'd', 'c', 'b', 'a'])\n",
    "\n",
    "\n",
    "series_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T07:57:44.971470Z",
     "start_time": "2021-01-02T07:57:44.965715Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "series_2 = pd.Series([0.0, 1.0, 2.0, 3.0, 4.0, np.nan],\n",
    "                     index=['f', 'e', 'd', 'c', 'b', 'a'])\n",
    "\n",
    "\n",
    "series_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "If `series_1` is null then `series_2`, otherwise `series_1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T07:58:17.319043Z",
     "start_time": "2021-01-02T07:58:17.313914Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.where(pd.isnull(series_1), series_2, series_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Pandas Series object has a `combine_first()` method, which performs the equivalent of the above operation along with Pandas usual data alignment logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T08:02:45.697879Z",
     "start_time": "2021-01-02T08:02:45.690582Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "series_2[:-2].combine_first(series_1[2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There is a `combine()` method which takes a function and combines the series according to this function. The function takes two scalars as inputs and returns a single element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T08:05:51.201512Z",
     "start_time": "2021-01-02T08:05:51.192339Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "series_2.combine(series_1, max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T08:08:31.546255Z",
     "start_time": "2021-01-02T08:08:31.540089Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "series_2.combine(series_1, min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now, it's time to perform same operation for DataFrames to see how it works when we have DataFrame instead of Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T08:19:25.954567Z",
     "start_time": "2021-01-02T08:19:25.940520Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'a': [1., np.nan, 5., np.nan],\n",
    "                    'b': [np.nan, 2., np.nan, 6.],\n",
    "                    'c': range(2, 18, 4)})\n",
    "\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T08:19:48.569666Z",
     "start_time": "2021-01-02T08:19:48.560223Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'a': [5., 4., np.nan, 3., 7.],\n",
    "                    'b': [np.nan, 3., 4., 6., 8.]})\n",
    "\n",
    "\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T08:20:02.731482Z",
     "start_time": "2021-01-02T08:20:02.704995Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1.combine_first(df2) # Updates null elements with value in the same location in other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Pandas DataFrame `combine()` method takes two Series and produce Series or one single element. In other words, perform column-wise combine with another DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T08:31:40.192182Z",
     "start_time": "2021-01-02T08:31:40.179320Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1.combine(df2, np.minimum) # np.minimum performs elementwise min operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T08:31:56.645984Z",
     "start_time": "2021-01-02T08:31:56.637499Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1.combine(df2, np.maximum) # np.maximum performs elementwise max operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T08:33:25.275506Z",
     "start_time": "2021-01-02T08:33:25.263204Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1.combine(df2, np.add) # np.add performs elementwise summution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Joining and Concatenation\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "* `join()` - for combining data on a key column or an index\n",
    "\n",
    "\n",
    "    * supports inner/left (default)/right/full\n",
    "    * can join multiple DataFrames at a time\n",
    "    * supports index-index joins\n",
    "\n",
    "\n",
    "* `concat()` - for combining DataFrames across rows or columns\n",
    "\n",
    "\n",
    "    * supports inner/full (default)\n",
    "    * can join multiple DataFrames at a time\n",
    "    * supports index-index joins\n",
    "\n",
    "\n",
    "\n",
    "Under the hood, `join()` uses `merge()`, but it provides a more efficient way to join DataFrames than a fully specified `merge()` method. Moreover, `join()` can be used to combine together many DataFrame objects having the same or similar indexes but non-overlapping columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Join\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T09:01:22.508563Z",
     "start_time": "2021-01-03T09:01:22.502760Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T09:01:23.915297Z",
     "start_time": "2021-01-03T09:01:23.910203Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As we have overlapping columns in `left` and `right` DataFrame, we have to use `lsuffix` and `rsuffix` arguments while calling `join()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T09:10:30.242522Z",
     "start_time": "2021-01-03T09:10:30.233817Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "left.join(right, lsuffix=\"_left\", rsuffix=\"_right\") # By default performs LEFT join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T09:10:40.330683Z",
     "start_time": "2021-01-03T09:10:40.323572Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "left.join(right, lsuffix=\"_caller\", rsuffix=\"_other\", how=\"inner\") # INNER join index-to-index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`join()` method can join several DataFrames compared to `merge()` method which only can join two at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T09:40:57.905483Z",
     "start_time": "2021-01-03T09:40:57.899054Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "middle = pd.DataFrame({'key_1': ['A', 'B', 'C', 'D'],\n",
    "                       'middle_value': [1, 2, 3, 4]})\n",
    "\n",
    "\n",
    "middle = middle.set_index(\"key_1\")\n",
    "\n",
    "\n",
    "middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T09:40:59.377601Z",
     "start_time": "2021-01-03T09:40:59.373300Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "left = left.rename({\"key_2\":\"left_key_2\", \"value\":\"left_value\"}, axis=1)\n",
    "\n",
    "right = right.rename({\"key_2\":\"right_key_2\", \"value\":\"right_value\"}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T09:40:59.954592Z",
     "start_time": "2021-01-03T09:40:59.935841Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "left.join([middle, right], how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Concatenation\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Concatenation is a bit different from the merging techniques we saw above. With merging, we can expect the resulting dataset to have rows from the first DataFrame mixed with the second DataFrame based on some commonality. Depending on the type of merge, we might also lose rows that don’t have matches in the other dataset.\n",
    "\n",
    "With concatenation, your datasets are just stacked together along an axis — either the row axis or column axis. Visually, a concatenation with no parameters along rows would look like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Reference\n",
    "\n",
    "[Merge, join, concatenate and compare](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Row Concatenation**\n",
    "\n",
    "\n",
    "![Concatenation](images/concat_row.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T09:47:03.808628Z",
     "start_time": "2021-01-03T09:47:03.802950Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "left = (left.reset_index(drop=True)\n",
    "            .rename({\"left_value\":\"value\"}, axis=1))\n",
    "\n",
    "left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T09:48:00.854135Z",
     "start_time": "2021-01-03T09:48:00.847419Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "middle.insert(0, \"middle_key_2\", list(middle.index.str.lower()))\n",
    "\n",
    "middle = (middle.reset_index(drop=True)\n",
    "                .rename({\"middle_value\": \"value\"}, axis=1))\n",
    "\n",
    "middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T09:49:07.983155Z",
     "start_time": "2021-01-03T09:49:07.976309Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "right = (right.drop(\"new_value\", axis=1)\n",
    "              .reset_index(drop=True)\n",
    "              .rename({\"right_value\": \"value\"}, axis=1))\n",
    "\n",
    "right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T09:52:43.586052Z",
     "start_time": "2021-01-03T09:52:43.577009Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.concat([left, middle, right], axis=0) # By default performs OUTER join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T09:57:28.364573Z",
     "start_time": "2021-01-03T09:57:28.355175Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.concat([left, middle, right], axis=0, join=\"inner\") # INNER join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T09:58:03.971927Z",
     "start_time": "2021-01-03T09:58:03.962918Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.concat([left, middle, right], keys=[\"left_key_2\", \"middle_key_2\", \"right_key_2\"], axis=0) # Creates MultiIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Column Concatenation**\n",
    "\n",
    "\n",
    "![Concatenation](images/concat_column.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T09:55:33.824661Z",
     "start_time": "2021-01-03T09:55:33.817471Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.concat([left, middle, right], axis=1) # Concatenation along vertical axis - adding columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T09:56:19.034628Z",
     "start_time": "2021-01-03T09:56:19.021658Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.concat([left, middle, right], keys=[\"left_key_2\", \"middle_key_2\", \"right_key_2\"], axis=1) # Column-wise MultiIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Reshaping and Pivoting\n",
    "\n",
    "---\n",
    "\n",
    "Sometimes, we need to reshape our DataFrame, meaning that to change its format. Reshaping can be done in two ways. We can convert our long format data into wide format or vice versa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Reference\n",
    "\n",
    "\n",
    "[Reshaping and pivot tables](https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Reshaping Rows and Colums with `stack()` and `unstack()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T12:25:21.707191Z",
     "start_time": "2021-01-03T12:25:21.696181Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "monthly_data = pd.read_csv(\"data/monthly_data.csv\")\n",
    "\n",
    "\n",
    "monthly_data = monthly_data.set_index('YYYY') # Set \"YYYY\" column as index\n",
    "\n",
    "\n",
    "monthly_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`stack()` method moves data from rows into a single column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T12:29:22.765670Z",
     "start_time": "2021-01-03T12:29:22.759819Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stacked_monthly_data = monthly_data.stack()\n",
    "\n",
    "stacked_monthly_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`unstack()` takes the inner index level and creates a column for every unique index. It then moves the data into these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T12:34:03.199451Z",
     "start_time": "2021-01-03T12:34:03.184276Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stacked_monthly_data.unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`unstack()` might introduce missing data if all of the values in the level aren’t found in each of the subgroups. Let consider the following example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T12:40:57.251391Z",
     "start_time": "2021-01-03T12:40:57.244951Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "s1 = pd.Series([0, 1, 2, 3], index=[\"a\", \"b\", \"c\", \"d\"])\n",
    "\n",
    "s2 = pd.Series([4, 5, 6], index=[\"c\", \"d\", \"e\"])\n",
    "\n",
    "test_data = pd.concat([s1, s2], keys=[\"one\", \"two\"])\n",
    "\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T12:41:09.538536Z",
     "start_time": "2021-01-03T12:41:09.520599Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_data.unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What if we `unstack()` the initial DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T12:32:34.023714Z",
     "start_time": "2021-01-03T12:32:34.015790Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "monthly_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T12:33:37.952609Z",
     "start_time": "2021-01-03T12:33:37.946169Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "unstacked_monthly_data = monthly_data.unstack()\n",
    "\n",
    "unstacked_monthly_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let convert unstacked initial DataFrame from Pandas Series to Pandas DataFrame and then reset index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T12:35:42.644332Z",
     "start_time": "2021-01-03T12:35:42.635390Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(unstacked_monthly_data).reset_index() # We converted Wide format data into Long format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Wide to Long format\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "When converting wide format into long format, we merge multiple columns into one, which produces a DataFrame that is longer than the input.\n",
    "\n",
    "`melt()` is the opposite of `pivot()` as it moves the data from the rows into a single column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T12:06:54.091845Z",
     "start_time": "2021-01-03T12:06:54.083537Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wide_data = pd.DataFrame([[\"Mary\", 6, 4, 5, ],\n",
    "                          [\"John\", 7, 8, 7],\n",
    "                          [\"Ann\", 6, 7, 9],\n",
    "                          [\"Pete\", 6, 5, 5],\n",
    "                          [\"Laura\", 5, 2, 7]], \n",
    "                         columns = [\"name\", \"test_1\", \"test_2\", \"test_3\"])\n",
    "\n",
    "\n",
    "wide_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T12:09:34.968187Z",
     "start_time": "2021-01-03T12:09:34.959849Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.melt(wide_data, id_vars=[\"name\"]) # Returns Long format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T12:10:43.860313Z",
     "start_time": "2021-01-03T12:10:43.850098Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.melt(wide_data, id_vars=[\"name\"], value_vars=[\"test_1\"]) # Use one column as value variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T12:10:55.521567Z",
     "start_time": "2021-01-03T12:10:55.512100Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.melt(wide_data, id_vars=[\"name\"], value_vars=[\"test_1\", \"test_2\"]) # Use two columns as value variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "After converting our DataFrame from wide to long format, we see that there are two new columns, `variable` and `value`. We can change them while converting by specifying `var_name` and `value_name` arguments, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T12:13:55.108617Z",
     "start_time": "2021-01-03T12:13:55.099762Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.melt(wide_data, id_vars=[\"name\"], var_name=\"test\", value_name=\"grades\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Long to Wide format\n",
    "\n",
    "---\n",
    "\n",
    "To convert Wide format data into a Long format, we use `pivot()` method. `pivot()` moves data from rows into columns.\n",
    "\n",
    "Let first create long format data. `pivot()` is an inverse operation to Pandas `melt()` operation we saw above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T11:25:48.796263Z",
     "start_time": "2021-01-03T11:25:48.785337Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "raw_data = {\"patient\": [1, 1, 1, 2, 2], \n",
    "            \"obs\": [1, 2, 3, 1, 2], \n",
    "            \"treatment\": [0, 1, 0, 1, 0],\n",
    "            \"score\": [6252, 24243, 2345, 2342, 23525]}\n",
    "\n",
    "\n",
    "long_data = pd.DataFrame(raw_data, columns = ['patient', 'obs', 'treatment', 'score'])\n",
    "\n",
    "\n",
    "long_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T11:26:05.890667Z",
     "start_time": "2021-01-03T11:26:05.875973Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "wide_data = long_data.pivot(index=\"patient\", columns=\"obs\", values=\"score\")\n",
    "\n",
    "\n",
    "wide_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Groupby\n",
    "\n",
    "---\n",
    "\n",
    "Sometimes we want to select data based on groups and understand aggregated data on a group level. Fortunately Pandas has a `groupby()` method to speed up such task. The idea behind the groupby() function is  that it takes some DataFrame, splits it into chunks based on some key values, applies computation on those  chunks, then combines the results back together into another DataFrame. In Pandas this is referred as the `split-apply-combine` pattern.\n",
    "\n",
    "\n",
    "![Split_Apply_Combine](images/split_apply_combine.png)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "* **Splitting** the data into groups based on some criteria.\n",
    "\n",
    "\n",
    "* **Applying** a function to each group independently.\n",
    "\n",
    "\n",
    "* **Combining** the results into a data structure.\n",
    "\n",
    "\n",
    "$$\n",
    "$$\n",
    "\n",
    "The **Split** step is the most straightforward. We may wish to split the data set into groups based on some key(s) and do something with those groups.\n",
    "\n",
    "\n",
    "In the **Apply** step we're doing one of the following:\n",
    "\n",
    "\n",
    "* Aggregation\n",
    "\n",
    "\n",
    "    * Compute group sum, mean, variance, etc.\n",
    "    * Compute group size/count\n",
    "\n",
    "\n",
    "* Transformation\n",
    "\n",
    "\n",
    "    * Standardize data in a group\n",
    "    * Filling NAs within groups with a value derived from each group\n",
    "    \n",
    "    \n",
    "* Filtration\n",
    "\n",
    "\n",
    "    * Filtering out data based on some criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Reference\n",
    "\n",
    "\n",
    "\n",
    "[Group by: split-apply-combine](https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html)\n",
    "\n",
    "\n",
    "[Grouping](https://pandas.pydata.org/pandas-docs/stable/user_guide/cookbook.html#grouping)\n",
    "\n",
    "\n",
    "[Combining with stats and GroupBy](https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html#combining-with-stats-and-groupby)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T05:47:50.299045Z",
     "start_time": "2021-01-04T05:47:50.294884Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "series = pd.Series(data=[0, 5, 10, 5, 10, 15, 10, 15, 20],\n",
    "                   index=[\"A\", \"B\", \"C\", \"A\", \"B\", \"C\", \"A\", \"B\", \"C\"])\n",
    "\n",
    "\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T05:47:50.793869Z",
     "start_time": "2021-01-04T05:47:50.788484Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "series.groupby(by=series.index) # Retruns SeriesGroupBy object. Does not compute anything yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T05:47:51.333668Z",
     "start_time": "2021-01-04T05:47:51.325742Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "series.groupby(by=series.index).sum() # Group by index and then sum them up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can calculate several aggregation functions, such as count, mean, sum, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T05:47:52.386763Z",
     "start_time": "2021-01-04T05:47:52.375521Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "series.groupby(by=series.index).agg([np.sum, np.mean, np.min, np.max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T05:49:57.983508Z",
     "start_time": "2021-01-04T05:49:57.973129Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "series.groupby(by=series.index).agg([\"sum\", \"mean\", \"count\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Let see how `groupby()` works with DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T05:30:08.650781Z",
     "start_time": "2021-01-04T05:30:08.597863Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "athletes = pd.read_csv(\"data/athletes.csv\")\n",
    "\n",
    "\n",
    "athletes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Like Series groupby, DataFrame groupby returns `DataFrameGroupBy` object. Actually. it's a DataFrame. Hence, we can perform DataFrame common operations, such as slicing, filtering, and aggregation by columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T05:30:09.866077Z",
     "start_time": "2021-01-04T05:30:09.863026Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "athletes.groupby(by=[\"nationality\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Calling an aggregation function on the `GroupBy` object applies the calculation for every group and constructs a DataFrame with the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T05:30:10.419657Z",
     "start_time": "2021-01-04T05:30:10.401496Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "athletes.groupby(by=[\"nationality\"])[[\"height\", \"weight\"]].mean() # Mean height and weight by nationality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T05:30:10.897352Z",
     "start_time": "2021-01-04T05:30:10.881314Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "athletes.groupby(by=[\"sex\", \"nationality\"])[[\"height\", \"weight\"]].mean() # Mean height and weight by sex and nationality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let count the number of medals by country. To do, we have to group by country and then count the amount of medals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T05:30:11.818390Z",
     "start_time": "2021-01-04T05:30:11.809422Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "medal_counts = athletes.groupby(by=[\"nationality\"])[[\"gold\", \"silver\", \"bronze\"]].sum()\n",
    "\n",
    "medal_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Not very informative right? Let sort the resulted DataFrame by values and see which country got the highest number of medals in each type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T05:30:12.623688Z",
     "start_time": "2021-01-04T05:30:12.614641Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "medal_counts.sort_values(by=[\"gold\", \"silver\", \"bronze\"], ascending=[False, False, False]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T05:57:48.284897Z",
     "start_time": "2021-01-04T05:57:48.277368Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "medal_counts.nlargest(n=5, columns=[\"gold\", \"silver\", \"bronze\"]) # Same as above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Medal counts by sex and country. Are female better than male?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T05:58:31.762587Z",
     "start_time": "2021-01-04T05:58:31.750416Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "medal_counts_by_sex = athletes.groupby(by=[\"nationality\", \"sex\"])[[\"gold\", \"silver\", \"bronze\"]].sum()\n",
    "\n",
    "\n",
    "medal_counts_by_sex.nlargest(5, [\"gold\", \"silver\", \"bronze\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T05:30:16.423616Z",
     "start_time": "2021-01-04T05:30:16.406286Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "athletes[athletes[\"nationality\"]==\"RUS\"][[\"sex\", \"gold\", \"silver\", \"bronze\"]].groupby(\"sex\").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> <font color='red'>Do you notice weird thing in the above `groupby()`? What is it? Why it happened?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let see the average height and weight by sex and sport. We can even group them by country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T06:45:27.102778Z",
     "start_time": "2021-01-04T06:45:27.087559Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "athletes.groupby([\"sport\", \"sex\"])[[\"weight\", \"height\"]].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`groupby()` is a powerful and commonly used tool for data cleaning and data analysis. Once you have grouped the data by some category you have a DataFrame of just those values and you can conduct aggregated analysis on the segments that you are interested in. The `groupby()` method follows a `split-apply-combine` approach - first the data is split into subgroups, then you can apply some transformation, filtering, or aggregation, and then the results are combined automatically by Pandas for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Pivot Table\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "A pivot table is a way of summarizing data in a DataFrame for a particular purpose. It makes heavy use of\n",
    "the aggregation function. A pivot table is itself a DataFrame, where the rows represent one variable that\n",
    "you're interested in, the columns another, and the cell's some aggregate value. A pivot table also tends to\n",
    "includes marginal values as well, which are the sums for each column and row. This allows you to be able to\n",
    "see the relationship between two variables at just a glance.\n",
    "\n",
    "\n",
    "Behind the `pivot_table()` method of Pandas, there is `groupby()` facility combined with reshape operations utilizing hierarchical indexing.\n",
    "\n",
    "\n",
    "> Pandas `pivot()` and `pivot_table()` are not the same. They are similar and in some cases they are complements.\n",
    "\n",
    "\n",
    "\n",
    "`pivot_table()` is a generalization of `pivot()` that can handle duplicate values for one pivoted index/column pair, whereas `pivot()` can’t deal with duplicate values.\n",
    "\n",
    "$$\n",
    "$$\n",
    "\n",
    "\n",
    "**Pandas `pivot_table()` has the same functionality as excel pivot table**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Reference\n",
    "\n",
    "\n",
    "[Pivot tables](https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html#pivot-tables)\n",
    "\n",
    "\n",
    "[Pandas Pivot Table Explained](https://pbpython.com/pandas-pivot-table-explained.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T11:36:50.693426Z",
     "start_time": "2021-01-04T11:36:50.684145Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pivot_df = pd.DataFrame({\"A\": [\"foo\", \"foo\", \"foo\", \"foo\", \"foo\",\n",
    "                               \"bar\", \"bar\", \"bar\", \"bar\"],\n",
    "                         \"B\": [\"one\", \"one\", \"one\", \"two\", \"two\",\n",
    "                               \"one\", \"one\", \"two\", \"two\"],\n",
    "                         \"C\": [\"small\", \"large\", \"large\", \"small\",\n",
    "                               \"small\", \"large\", \"small\", \"small\", \"large\"],\n",
    "                         \"D\": [1, 2, 2, 3, 3, 4, 5, 6, 7],\n",
    "                         \"E\": [2, 4, 5, 5, 6, 6, 8, 9, 9]})\n",
    "\n",
    "\n",
    "\n",
    "pivot_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The simplest Pivot Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T11:37:05.941254Z",
     "start_time": "2021-01-04T11:37:05.923755Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pivot_df.pivot_table(index=[\"A\"]) # Returns average of only numerical columns by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can pivot our DataFrame by two or more columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T11:37:49.908019Z",
     "start_time": "2021-01-04T11:37:49.896771Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pivot_df.pivot_table(index=[\"A\",\"B\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Pivot Table with column values\n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "One of the confusing points with the `pivot_table()` is the use of `columns` and `values` . Remember, `columns` are optional - they provide an additional way to segment the actual `values` you care about. The aggregation functions are applied to the `values` you list.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T11:39:55.403602Z",
     "start_time": "2021-01-04T11:39:55.384218Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pivot_df.pivot_table(index=[\"A\", \"B\"],\n",
    "                     columns=[\"E\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T11:40:26.383200Z",
     "start_time": "2021-01-04T11:40:26.351693Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pivot_df.pivot_table(index=[\"A\", \"B\"],\n",
    "                     columns=[\"C\"],\n",
    "                     aggfunc=[\"mean\", \"sum\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Fully-fledged Pivot Table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T11:43:37.089161Z",
     "start_time": "2021-01-04T11:43:37.061054Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pivot_df.pivot_table(index=[\"A\", \"B\"],\n",
    "                     columns=[\"C\"],\n",
    "                     values=\"D\",\n",
    "                     aggfunc=\"sum\",\n",
    "                     margins=True,\n",
    "                     margins_name=\"Total\",\n",
    "                     fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T11:45:55.740587Z",
     "start_time": "2021-01-04T11:45:55.708941Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pivot_df.pivot_table(index=[\"A\", \"B\"],\n",
    "                     columns=[\"C\"],\n",
    "                     values=[\"D\", \"E\"],\n",
    "                     aggfunc=\"sum\",\n",
    "                     margins=True,\n",
    "                     margins_name=\"Total\",\n",
    "                     fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`Pivot Tables` are incredibly useful when dealing with numeric data, especially if you're trying to summarize the data in some form. You'll regularly be creating new pivot tables on slices of data, whether you're exploring the data yourself or preparing data for others to report on. And of course, you can pass any function you want to the aggregate function, including those that you define yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Cross-Tabulation\n",
    "\n",
    "---\n",
    "\n",
    "A cross-tabulation (or crosstab for short) is a special case of a pivot table that computes group frequencies, unless an array of values and an aggregation function are passed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Reference\n",
    "\n",
    "\n",
    "[Cross tabulations](https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html#cross-tabulations)\n",
    "\n",
    "\n",
    "[Pandas Crosstab Explained](https://pbpython.com/pandas-crosstab.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Define column names for the data, since the data does not have any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T12:03:46.170674Z",
     "start_time": "2021-01-04T12:03:46.168282Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "headers = [\"symboling\", \"normalized_losses\", \"make\", \"fuel_type\", \"aspiration\",\n",
    "           \"num_doors\", \"body_style\", \"drive_wheels\", \"engine_location\",\n",
    "           \"wheel_base\", \"length\", \"width\", \"height\", \"curb_weight\",\n",
    "           \"engine_type\", \"num_cylinders\", \"engine_size\", \"fuel_system\",\n",
    "           \"bore\", \"stroke\", \"compression_ratio\", \"horsepower\", \"peak_rpm\",\n",
    "           \"city_mpg\", \"highway_mpg\", \"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T12:04:47.291723Z",
     "start_time": "2021-01-04T12:04:47.286608Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cross_df = pd.read_csv(\"data/automobile.data\",\n",
    "                       header=None,\n",
    "                       names=headers,\n",
    "                       na_values=\"?\") # Convert \"?\" into NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T12:05:19.642026Z",
     "start_time": "2021-01-04T12:05:19.610228Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cross_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T12:04:49.661616Z",
     "start_time": "2021-01-04T12:04:49.634489Z"
    },
    "hidden": true
   },
   "source": [
    "The DataFrame contains many rows and is not convenient to work with. Let extract only top automobile producers, such as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T12:06:43.166274Z",
     "start_time": "2021-01-04T12:06:43.164032Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "models = [\"toyota\", \"nissan\", \"mazda\", \"honda\",\n",
    "          \"mitsubishi\", \"subaru\", \"volkswagen\", \"volvo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T12:07:56.759663Z",
     "start_time": "2021-01-04T12:07:56.739925Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cross_df = cross_df[cross_df[\"make\"].isin(models)]\n",
    "\n",
    "cross_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The simplest `cross-tab`. Let calculate how many different `body_style` these car makers made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T12:10:53.496615Z",
     "start_time": "2021-01-04T12:10:53.478443Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.crosstab(index=cross_df[\"make\"],\n",
    "            columns=cross_df[\"body_style\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T12:12:05.506999Z",
     "start_time": "2021-01-04T12:12:05.495691Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cross_df.groupby([\"make\", \"body_style\"])[\"body_style\"].count().unstack().fillna(0) # Same as above, but with groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T12:12:54.624592Z",
     "start_time": "2021-01-04T12:12:54.602506Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cross_df.pivot_table(index=\"make\", columns=\"body_style\", aggfunc={\"body_style\": len}, fill_value=0) # Same with pivot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T12:15:15.130231Z",
     "start_time": "2021-01-04T12:15:15.101321Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.crosstab(index=cross_df[\"make\"],\n",
    "            columns=cross_df[\"num_doors\"],\n",
    "            margins=True,\n",
    "            margins_name=\"Total\") # Include totals across rows and columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Cross-Tab in not only used to count the frequencies. Let calculate the average price across car makers and break it down by car type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T12:35:32.813294Z",
     "start_time": "2021-01-04T12:35:32.790999Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.crosstab(index=cross_df[\"make\"],\n",
    "            columns=cross_df[\"body_style\"],\n",
    "            values=cross_df[\"price\"],\n",
    "            aggfunc=\"mean\").round(0).fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Pandas `crosstab()` is even smarter in a way that we can pass in multiple columns and it will group them. For example: If we want to see how the data is distributed by front wheel drive (fwd) and rear wheel drive (rwd), we can include the `drive_wheels` column by including it in the list of valid columns in the second argument to the `crosstab()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T13:50:18.226157Z",
     "start_time": "2021-01-04T13:50:18.203202Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.crosstab(cross_df[\"make\"],\n",
    "            [cross_df[\"body_style\"],\n",
    "             cross_df[\"drive_wheels\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T13:53:44.432584Z",
     "start_time": "2021-01-04T13:53:44.396825Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.crosstab([cross_df[\"make\"], cross_df[\"num_doors\"]],\n",
    "            [cross_df[\"body_style\"],\n",
    "             cross_df[\"drive_wheels\"]],\n",
    "            rownames=[\"Auto Manufacturer\", \"Doors\"],\n",
    "            colnames=['Body Style', \"Drive Type\"],\n",
    "            dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "---\n",
    "\n",
    "Now you know how to merge and concatenate datasets together. You will find such functions very useful for\n",
    "combining data to get more complex or complicated results and to do analysis with. A solid understanding of\n",
    "how to merge data is absolutely essentially when you are procuring, cleaning, and manipulating data. It's\n",
    "worth knowing how to join different datasets quickly, and the different options you can use when joining\n",
    "datasets, and I would encourage you to check out the pandas docs for joining and concatenating data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
